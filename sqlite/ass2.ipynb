{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import OperationalError\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def writeres(fn,res):\n",
    "    f=open(fn,'w')\n",
    "    f.write(str(res))\n",
    "    f.close\n",
    "    \n",
    "    return open(fn).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m=c.execute(' SELECT sql FROM sqlite_master')\n",
    "m=c.execute('PRAGMA table_info( Frequency)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#'σdocid=10398_txt_earn(frequency)'\n",
    "m=c.execute('SELECT count(*) FROM Frequency WHERE DOCID=\"10398_txt_earn\"')\n",
    "f=open('part_a.txt','w')\n",
    "f.write(str(m.fetchall()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#πterm(σdocid=10398_txt_earn and count=1(frequency))\n",
    "#part_b.txt\n",
    "m=c.execute('SELECT count(*) FROM Frequency WHERE DOCID=\"10398_txt_earn\" and COUNT=1')\n",
    "f=open('part_b.txt','w')\n",
    "f.write(str(m.fetchall()[0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#πterm(σdocid=10398_txt_earn and count=1(frequency)) U πterm(σdocid=925_txt_trade and count=1(frequency))\n",
    "m=c.execute('SELECT count(*) FROM  Frequency WHERE DOCID=\"10398_txt_earn\" and COUNT=1 union SELECT count(*) FROM Frequency WHERE DOCID=\"925_txt_trade\" and COUNT=1')\n",
    "m=c.execute('SELECT * FROM  Frequency WHERE DOCID=\"10398_txt_earn\" and COUNT=1 union all SELECT * FROM Frequency WHERE DOCID=\"925_txt_trade\" and COUNT=1')\n",
    "\n",
    "gt=m.fetchall()\n",
    "len(gt)\n",
    "#f=open('part_c.txt','w')\n",
    "#f.write(str(sum(zip(*gt)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query='''\n",
    "SELECT count (*) From (\n",
    "    SELECT F1.TERM FROM  Frequency F1\n",
    "    WHERE F1.DOCID=\"10398_txt_earn\" and F1.COUNT=1\n",
    "    UNION\n",
    "    SELECT F2.TERM FROM  Frequency F2\n",
    "    WHERE F2.DOCID=\"925_txt_trade\" and F2.COUNT=1\n",
    ") x;\n",
    "'''\n",
    "res=c.execute(query).fetchall()\n",
    "f=open('part_c.txt','w')\n",
    "f.write(str(res[0][0]))\n",
    "f.close\n",
    "!cat part_c.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat part_c.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Write a SQL statement to count the number of unique documents\n",
    "#containing the word \"law\" or containing the word \"legal\" \n",
    "#(If a document contains both law and legal, it should only be counted once)\n",
    "conn = sqlite3.connect('reuters.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "query='''\n",
    "SELECT  COUNT(*) FROM\n",
    "(SELECT DISTINCT F1.DOCID\n",
    "    FROM Frequency F1\n",
    "    WHERE F1.TERM LIKE 'legal' OR F1.TERM LIKE 'law')\n",
    ";\n",
    "'''\n",
    "res=c.execute(query).fetchall()\n",
    "c.close()\n",
    "f=open('part_d.txt','w')\n",
    "f.write(str(res[0][0]))\n",
    "f.close\n",
    "!cat part_d.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Write a SQL statement to find all documents that have more than 300 total terms,\n",
    "#including duplicate terms. (Hint: You can use the HAVING clause, or you can use a nested query.\n",
    "#Another hint: Remember that the count column contains the term frequencies, and you want to consider duplicates.)\n",
    "#(docid, term_count)\n",
    "fn='part_e.txt'\n",
    "conn = sqlite3.connect('reuters.db')\n",
    "c = conn.cursor()\n",
    "query='''\n",
    "    \n",
    "    SELECT * FROM\n",
    "    (SELECT F1.DOCID,SUBSTR(F1.DOCID,INSTR(F1.DOCID,'_')+5),F1.TERM,SUM(F1.COUNT)\n",
    "    FROM Frequency F1\n",
    "    GROUP BY F1.DOCID\n",
    "    HAVING SUM(F1.COUNT)>300\n",
    "    ORDER BY  SUBSTR(F1.DOCID,INSTR(F1.DOCID,'_')+5) ASC )\n",
    "    \n",
    ";\n",
    "'''\n",
    "query='''\n",
    "    \n",
    "    SELECT  sum(x.termcount) FROM\n",
    "    (SELECT  F1.DOCID,SUM(F1.COUNT) as termcount\n",
    "    FROM Frequency F1\n",
    "    GROUP BY F1.DOCID\n",
    "    HAVING COUNT(F1.DOCID)*SUM(F1.COUNT)>300\n",
    "    )x\n",
    "    \n",
    ";\n",
    "'''\n",
    "query='select DISTINCT term || \",\" from (select (f.term)as term  from frequency f where f.docid=\"10000_txt_earn\")'\n",
    "query='''\n",
    "select DISTINCT sum(x.c) from\n",
    "(SELECT DISTINCT f.docid,count(f.docid) as c\n",
    "FROM frequency f GROUP BY f.docid having sum(f.count)>300)x\n",
    "'''\n",
    "queryCorrect='''\n",
    "select count(*) from \n",
    "(select distinct  f.docid,sum(f.term) \n",
    "from frequency f \n",
    "group by f.docid \n",
    "having sum(f.term)>300); \n",
    "\n",
    "'''\n",
    "queryGrader='''\n",
    "select count(*) from \n",
    "(select distinct  f.docid,count(f.term) \n",
    "from frequency f \n",
    "group by f.docid \n",
    "having count(f.term)>300); \n",
    "\n",
    "'''\n",
    "res=c.execute(queryGrader).fetchall()\n",
    "c.close()\n",
    "writeres(fn,res[0][0])\n",
    "!cat \"$fn\"\n",
    "#sum(zip(*res)[1])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' two words: Write a SQL statement to count the \n",
    "number of unique documents that contain both the word 'transactions' and the word 'world'.\n",
    "(Hint: Find the docs that contain one word and the \n",
    "docs that contain the other word separately, then find the intersection.)\n",
    "'''\n",
    "fn='part_f.txt'\n",
    "conn = sqlite3.connect('reuters.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "queryGrader='''\n",
    "SELECT count(*) from (SELECT * \n",
    "FROM frequency f1 \n",
    "WHERE f1.term ='transactions')x\n",
    "\n",
    "INNER JOIN\n",
    "\n",
    "(SELECT * \n",
    "FROM frequency f2\n",
    "WHERE f2.term ='world')y\n",
    "\n",
    "ON\n",
    "x.docid=y.docid\n",
    "'''\n",
    "res=c.execute(queryGrader).fetchall()\n",
    "c.close()\n",
    "writeres(fn,res[0][0])\n",
    "!cat \"$fn\"\n",
    "#sum(zip(*res)[1])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' matrix product\n",
    "'''\n",
    "fn='part_g.txt'\n",
    "conn = sqlite3.connect('matrix.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "queryGrader='''\n",
    "select res from\n",
    "(SELECT a.row_num as r, b.col_num as c, SUM(a.value*b.value) as res\n",
    "FROM a, b\n",
    "WHERE a.col_num = b.row_num\n",
    "GROUP BY a.row_num, b.col_num)x where x.r=2 and x.c=3 ;\n",
    "'''\n",
    "res=c.execute(queryGrader).fetchall()\n",
    "c.close()\n",
    "writeres(fn,res[0][0])\n",
    "!cat \"$fn\"\n",
    "#sum(zip(*res)[1])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(19,)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' similariy\n",
    "'''\n",
    "fn='part_h.txt'\n",
    "conn = sqlite3.connect('reuters.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "queryGrader='''\n",
    "CREATE INDEX index_name\n",
    "on FREQUENCY (DOCID, TERM);\n",
    "'''\n",
    "queryGrader='''\n",
    "SELECT SUM(S) FROM\n",
    "(SELECT F1T,F2T,SUM(Y.F2C*X.F1C) AS S FROM \n",
    "(SELECT F1.TERM AS F1T,F1.COUNT AS F1C FROM FREQUENCY F1 \n",
    "    WHERE F1.DOCID='10080_txt_crude')X,\n",
    "\n",
    "(SELECT F2.TERM AS F2T,F2.COUNT  AS F2C FROM FREQUENCY F2 \n",
    "    WHERE F2.DOCID='17035_txt_earn')Y\n",
    "WHERE Y.F2T=X.F1T\n",
    "GROUP BY Y.F2T,X.F1T)\n",
    "'''\n",
    "#'''\n",
    "#where x.r='10080_txt_crude' and x.c='17035_txt_earn';\n",
    "\n",
    "#'''\n",
    "res=c.execute(queryGrader).fetchall()\n",
    "c.close()\n",
    "writeres(fn,res[0][0])\n",
    "!cat \"$fn\"\n",
    "#sum(zip(*res)[1])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### keyword search: Find the best matching document to the keyword query \n",
    "\"washington taxes treasury\". \n",
    "You can add this set of keywords to the document corpus with a union of scalar queries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6,)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' similariy\n",
    "'''\n",
    "fn='part_i.txt'\n",
    "conn = sqlite3.connect('reuters.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "view='''\n",
    "CREATE VIEW query AS\n",
    "SELECT * FROM frequency\n",
    "UNION\n",
    "SELECT 'q' as docid, 'washington' as term, 1 as count \n",
    "UNION\n",
    "SELECT 'q' as docid, 'taxes' as term, 1 as count\n",
    "UNION \n",
    "SELECT 'q' as docid, 'treasury' as term, 1 as count\n",
    "\n",
    "'''\n",
    "queryGrader='''\n",
    "SELECT MAX(c) FROM\n",
    "(SELECT b.docid, b.term, SUM(a.count * b.count) as c\n",
    "FROM query a, Frequency b\n",
    "WHERE a.term = b.term \n",
    "AND a.docid = 'q'\n",
    "GROUP BY b.docid, b.term\n",
    "ORDER BY SUM(a.count * b.count) DESC);\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "#'''\n",
    "#where x.r='10080_txt_crude' and x.c='17035_txt_earn';\n",
    "\n",
    "#'''\n",
    "#res=c.execute(view)\n",
    "res=c.execute(queryGrader).fetchall()\n",
    "c.close()\n",
    "#writeres(fn,res[0][0])\n",
    "#!cat \"$fn\"\n",
    "#sum(zip(*res)[1])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT SUM(s) FROM\n",
      "(SELECT f1t,f2t,SUM(y.f2c*x.f1c) AS s FROM \n",
      "(SELECT f1.term AS f1t,f1.count AS f1c FROM frequency f1 \n",
      "    WHERE f1.docid='10080_txt_crude')x,\n",
      "\n",
      "(SELECT f2.term AS f2t,f2.count  AS f2c FROM frequency f2 \n",
      "    WHERE f2.docid='17035_txt_earn')y\n",
      "WHERE y.f2t=x.f1t\n",
      "GROUP BY y.f2t,x.f1t)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqllst=['SUM', 'FROM', 'SELECT', 'AS', 'WHERE','GROUP','BY','HAVING','ORDER']\n",
    "queryGrader=queryGrader.lower()\n",
    "for x in sqllst:\n",
    "    if queryGrader.count(x.lower())> 0:\n",
    "        queryGrader=queryGrader.replace(x.lower(),x)\n",
    "print(queryGrader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nselect SUM(s) from\\n(select f1t,f2t,SUM(y.f2c*x.f1c) as s from \\n(select f1.term as f1t,f1.count as f1c from frequency f1 \\n    where f1.docid='10080_txt_crude')x,\\n\\n(select f2.term as f2t,f2.count  as f2c from frequency f2 \\n    where f2.docid='17035_txt_earn')y\\nwhere y.f2t=x.f1t\\ngroup by y.f2t,x.f1t)\\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=sqllst[0]\n",
    "queryGrader=queryGrader.lower()\n",
    "queryGrader.count(x.lower())\n",
    "queryGrader.replace(x.lower(),x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
